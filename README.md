# Applied-Machine-Learning
## 1) [Instance Based Methods](https://github.com/karanpandyaa/Applied-Machine-Learning/blob/main/Instance_based_methods.pdf)

In this  I explored instance-based methods on two problems: handwritten digit recognition and temperature prediction. 

The aims of this were:

- Gain experience with machine learning methods based on retrieval, particularly K-means clustering, KNN classification, and KNN regression
- Get experience working with FAISS, which provides much faster search and is very useful in practice. 
- Learn how feature representations can impact performance
- Get practice selecting parameters using a validation set (stretch goals)

## 2)  [PCA and Linear Models](https://github.com/karanpandyaa/Applied-Machine-Learning/blob/main/PCA%20and%20Linear%20Models.pdf)

In this I explored linear projection, classification, and regression methods, again on digit recognition and temperature prediction. 

The aims of this were:
- Become familiar with PCA, Linear Logistic Regression, SVM, and Linear Regression methods. 
- Gain practice using visualizations and analysis to better understand the models and their effectiveness
- Gain experience in classification and regression applications

## 3) [PDFs and Outliers](https://github.com/karanpandyaa/Applied-Machine-Learning/blob/main/PDFs%20and%20Outliers.pdf)

In this I explored methods to estimate probability functions and to robustly estimate statistics in the presence of corrupted or missing data.

The aims of this were:
- Be able to estimate probability functions using several methods: per-feature 1D histograms, clustering for joint histograms, and mixture of Gaussian models.
- Be able to estimate statistics, such as mean, standard deviation, min, and max while being robust to data values that are incorrect or missing.

## 4) Trees and MLPs

In this I explored methods to add a penguin classification task to our repertoire and explore trees, ensemble, and MLPs. 

The aims of this were:
Explore the impact of model complexity while applying regression trees, random forests, and boosted regression trees. 
-Get experience with training and applying MLPs
-Gain exposure to using correct methodologies for learning rate selection and testing
-Get practice analyzing features and selecting and designing models for open problems


